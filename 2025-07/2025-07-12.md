# 2025-07-12

## 学んだこと
- エンベッディング(embedding)とは，単語や画像，音声などの高次元データを意味を保ったまま低次元のベクトルに変換する手法．
- 主に機械学習・深層学習で使用され，類似度の計算やクラスタリング，分類に役立つ．
- 単語エンベッディングの例として有名なのはWord2Vec，GloVe，BERTの出力ベクトルも使用される．
- エンベッディング同士の距離(例えばコサイン類似度)で，意味の近さを数値的に扱える． 

## メモ
- リンゴとバナナのエンベッディングは近く，リンゴと電車は離れている．
- ベクトル空間上での演算も可能(王-男性+女性=女王)
- 文字や画像などにも応用可能

## 所感
- 言語や画像などの直感的な情報が数値的に扱えるようになることは面白い

## 参考リンク
- [単語埋め込み (Word embeddings)](https://tensorflow.google.cn/tutorials/text/word_embeddings?hl=ja)
